{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-15 09:02:59,428] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v0')\n",
    "env = wrappers.Monitor(env,'./monitor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.n)\n",
    "print(env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:0 action:1 next_state:1 reward:0.0 done:False\n",
      "state:1 action:1 next_state:0 reward:0.0 done:False\n",
      "state:0 action:1 next_state:4 reward:0.0 done:False\n",
      "state:4 action:0 next_state:4 reward:0.0 done:False\n",
      "state:4 action:1 next_state:4 reward:0.0 done:False\n",
      "state:4 action:3 next_state:5 reward:0.0 done:True\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "for i in range(10):\n",
    "    #env.render()\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, prob = env.step(action)\n",
    "    print('state:{} action:{} next_state:{} reward:{} done:{}'.format(state, action, next_state, reward, done))\n",
    "    state = next_state\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "memory_size = 2000\n",
    "\n",
    "episodes = 2000\n",
    "steps = 100\n",
    "# changed from 0.95\n",
    "gamma = 0.95\n",
    "\n",
    "epsilon = 1\n",
    "epsilon_stop = 0.01\n",
    "epsilon_decay = 0.99\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bot = Sequential()\n",
    "bot.add(Dense(10, input_dim=16, activation='relu'))\n",
    "bot.add(Dense(4, activation='linear'))\n",
    "bot.compile(loss='mse', optimizer = Adam(learning_rate))\n",
    "memory = deque(maxlen=memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_lkup = np.eye(env.observation_space.n)\n",
    "action_lkup = np.eye(env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-15 09:03:11,304] Starting new video recorder writing to C:\\Users\\abjilani\\Desktop\\Projects\\DL Nanodegree\\my-experiments\\reinforcement learning\\monitor\\openaigym.video.3.17488.video000000.json\n",
      "[2017-07-15 09:03:11,319] Starting new video recorder writing to C:\\Users\\abjilani\\Desktop\\Projects\\DL Nanodegree\\my-experiments\\reinforcement learning\\monitor\\openaigym.video.3.17488.video000001.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:1 steps:6 total reward:-1.1 epsilon:1\n",
      "episode:2 steps:8 total reward:-1.1400000000000001 epsilon:0.99\n",
      "episode:3 steps:4 total reward:-1.06 epsilon:0.9801\n",
      "episode:4 steps:15 total reward:0.72 epsilon:0.9702989999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-15 09:03:12,703] Starting new video recorder writing to C:\\Users\\abjilani\\Desktop\\Projects\\DL Nanodegree\\my-experiments\\reinforcement learning\\monitor\\openaigym.video.3.17488.video000008.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:5 steps:9 total reward:-1.16 epsilon:0.96059601\n",
      "episode:6 steps:13 total reward:-1.24 epsilon:0.9509900498999999\n",
      "episode:7 steps:4 total reward:-1.06 epsilon:0.9414801494009999\n",
      "episode:8 steps:2 total reward:-1.02 epsilon:0.9320653479069899\n",
      "episode:9 steps:8 total reward:-1.1400000000000001 epsilon:0.92274469442792\n",
      "episode:10 steps:9 total reward:-1.16 epsilon:0.9135172474836407\n",
      "episode:11 steps:8 total reward:-1.1400000000000001 epsilon:0.9043820750088043\n",
      "episode:12 steps:13 total reward:-1.24 epsilon:0.8953382542587163\n",
      "episode:13 steps:3 total reward:-1.04 epsilon:0.8863848717161291\n",
      "episode:14 steps:8 total reward:-1.1400000000000001 epsilon:0.8775210229989678\n",
      "episode:15 steps:21 total reward:-1.4000000000000001 epsilon:0.8687458127689781\n",
      "episode:16 steps:13 total reward:-1.24 epsilon:0.8600583546412883\n",
      "episode:17 steps:2 total reward:-1.02 epsilon:0.8514577710948754\n",
      "episode:18 steps:13 total reward:-1.24 epsilon:0.8429431933839266\n",
      "episode:19 steps:5 total reward:-1.08 epsilon:0.8345137614500874\n",
      "episode:20 steps:4 total reward:-1.06 epsilon:0.8261686238355865\n",
      "episode:21 steps:5 total reward:-1.08 epsilon:0.8179069375972307\n",
      "episode:22 steps:9 total reward:-1.16 epsilon:0.8097278682212583\n",
      "episode:23 steps:10 total reward:0.8200000000000001 epsilon:0.8016305895390458\n",
      "episode:24 steps:4 total reward:-1.06 epsilon:0.7936142836436553\n",
      "episode:25 steps:5 total reward:-1.08 epsilon:0.7856781408072188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-15 09:03:13,615] Starting new video recorder writing to C:\\Users\\abjilani\\Desktop\\Projects\\DL Nanodegree\\my-experiments\\reinforcement learning\\monitor\\openaigym.video.3.17488.video000027.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:26 steps:12 total reward:-1.22 epsilon:0.7778213593991465\n",
      "episode:27 steps:3 total reward:-1.04 epsilon:0.7700431458051551\n",
      "episode:28 steps:7 total reward:-1.12 epsilon:0.7623427143471035\n",
      "episode:29 steps:11 total reward:-1.2 epsilon:0.7547192872036325\n",
      "episode:30 steps:8 total reward:-1.1400000000000001 epsilon:0.7471720943315961\n",
      "episode:31 steps:8 total reward:-1.1400000000000001 epsilon:0.7397003733882802\n",
      "episode:32 steps:4 total reward:-1.06 epsilon:0.7323033696543974\n",
      "episode:33 steps:11 total reward:-1.2 epsilon:0.7249803359578534\n",
      "episode:34 steps:7 total reward:-1.12 epsilon:0.7177305325982748\n",
      "episode:35 steps:11 total reward:-1.2 epsilon:0.7105532272722921\n",
      "episode:36 steps:14 total reward:-1.26 epsilon:0.7034476949995692\n",
      "episode:37 steps:17 total reward:-1.32 epsilon:0.6964132180495735\n",
      "episode:38 steps:9 total reward:-1.16 epsilon:0.6894490858690777\n",
      "episode:39 steps:30 total reward:-1.58 epsilon:0.682554595010387\n",
      "episode:40 steps:8 total reward:-1.1400000000000001 epsilon:0.6757290490602831\n",
      "episode:41 steps:23 total reward:-1.4400000000000002 epsilon:0.6689717585696803\n",
      "episode:42 steps:9 total reward:-1.16 epsilon:0.6622820409839835\n",
      "episode:43 steps:9 total reward:-1.16 epsilon:0.6556592205741436\n",
      "episode:44 steps:8 total reward:-1.1400000000000001 epsilon:0.6491026283684022\n",
      "episode:45 steps:15 total reward:-1.28 epsilon:0.6426116020847181\n",
      "episode:46 steps:13 total reward:-1.24 epsilon:0.6361854860638709\n",
      "episode:47 steps:12 total reward:-1.22 epsilon:0.6298236312032323\n",
      "episode:48 steps:5 total reward:-1.08 epsilon:0.6235253948912\n",
      "episode:49 steps:14 total reward:-1.26 epsilon:0.617290140942288\n",
      "episode:50 steps:4 total reward:-1.06 epsilon:0.6111172395328651\n",
      "episode:51 steps:9 total reward:-1.16 epsilon:0.6050060671375365\n",
      "episode:52 steps:8 total reward:-1.1400000000000001 epsilon:0.5989560064661611\n",
      "episode:53 steps:8 total reward:-1.1400000000000001 epsilon:0.5929664464014994\n",
      "episode:54 steps:4 total reward:-1.06 epsilon:0.5870367819374844\n",
      "episode:55 steps:8 total reward:-1.1400000000000001 epsilon:0.5811664141181095\n",
      "episode:56 steps:11 total reward:-1.2 epsilon:0.5753547499769285\n",
      "episode:57 steps:9 total reward:-1.16 epsilon:0.5696012024771592\n",
      "episode:58 steps:9 total reward:-1.16 epsilon:0.5639051904523876\n",
      "episode:59 steps:9 total reward:-1.16 epsilon:0.5582661385478638\n",
      "episode:60 steps:2 total reward:-1.02 epsilon:0.5526834771623851\n",
      "episode:61 steps:16 total reward:-1.3 epsilon:0.5471566423907612\n",
      "episode:62 steps:19 total reward:0.6399999999999999 epsilon:0.5416850759668536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-15 09:03:16,008] Starting new video recorder writing to C:\\Users\\abjilani\\Desktop\\Projects\\DL Nanodegree\\my-experiments\\reinforcement learning\\monitor\\openaigym.video.3.17488.video000064.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:63 steps:14 total reward:-1.26 epsilon:0.536268225207185\n",
      "episode:64 steps:17 total reward:-1.32 epsilon:0.5309055429551132\n",
      "episode:65 steps:12 total reward:-1.22 epsilon:0.525596487525562\n",
      "episode:66 steps:18 total reward:-1.34 epsilon:0.5203405226503064\n",
      "episode:67 steps:4 total reward:-1.06 epsilon:0.5151371174238033\n",
      "episode:68 steps:12 total reward:-1.22 epsilon:0.5099857462495653\n",
      "episode:69 steps:15 total reward:-1.28 epsilon:0.5048858887870696\n",
      "episode:70 steps:6 total reward:-1.1 epsilon:0.4998370298991989\n",
      "episode:71 steps:11 total reward:-1.2 epsilon:0.49483865960020695\n",
      "episode:72 steps:2 total reward:-1.02 epsilon:0.4898902730042049\n",
      "episode:73 steps:2 total reward:-1.02 epsilon:0.48499137027416284\n",
      "episode:74 steps:5 total reward:-1.08 epsilon:0.4801414565714212\n",
      "episode:75 steps:13 total reward:-1.24 epsilon:0.475340042005707\n",
      "episode:76 steps:13 total reward:-1.24 epsilon:0.47058664158564995\n",
      "episode:77 steps:15 total reward:-1.28 epsilon:0.4658807751697934\n",
      "episode:78 steps:6 total reward:-1.1 epsilon:0.4612219674180955\n",
      "episode:79 steps:6 total reward:0.9 epsilon:0.45660974774391455\n",
      "episode:80 steps:7 total reward:-1.12 epsilon:0.4520436502664754\n",
      "episode:81 steps:8 total reward:-1.1400000000000001 epsilon:0.44752321376381066\n",
      "episode:82 steps:9 total reward:-1.16 epsilon:0.44304798162617254\n",
      "episode:83 steps:2 total reward:-1.02 epsilon:0.4386175018099108\n",
      "episode:84 steps:8 total reward:-1.1400000000000001 epsilon:0.4342313267918117\n",
      "episode:85 steps:5 total reward:-1.08 epsilon:0.4298890135238936\n",
      "episode:86 steps:18 total reward:-1.34 epsilon:0.42559012338865465\n",
      "episode:87 steps:29 total reward:-1.56 epsilon:0.4213342221547681\n",
      "episode:88 steps:16 total reward:-1.3 epsilon:0.41712087993322045\n",
      "episode:89 steps:5 total reward:-1.08 epsilon:0.41294967113388825\n",
      "episode:90 steps:13 total reward:-1.24 epsilon:0.40882017442254937\n",
      "episode:91 steps:7 total reward:-1.12 epsilon:0.4047319726783239\n",
      "episode:92 steps:12 total reward:-1.22 epsilon:0.40068465295154065\n",
      "episode:93 steps:12 total reward:-1.22 epsilon:0.39667780642202527\n",
      "episode:94 steps:23 total reward:-1.4400000000000002 epsilon:0.392711028357805\n",
      "episode:95 steps:8 total reward:-1.1400000000000001 epsilon:0.38878391807422696\n",
      "episode:96 steps:2 total reward:-1.02 epsilon:0.3848960788934847\n",
      "episode:97 steps:29 total reward:-1.56 epsilon:0.38104711810454983\n",
      "episode:98 steps:12 total reward:-1.22 epsilon:0.37723664692350434\n",
      "episode:99 steps:14 total reward:-1.26 epsilon:0.37346428045426927\n",
      "episode:100 steps:6 total reward:-1.1 epsilon:0.36972963764972655\n",
      "episode:101 steps:12 total reward:0.78 epsilon:0.36603234127322926\n",
      "episode:102 steps:7 total reward:-1.12 epsilon:0.36237201786049694\n",
      "episode:103 steps:12 total reward:-1.22 epsilon:0.358748297681892\n",
      "episode:104 steps:15 total reward:-1.28 epsilon:0.35516081470507305\n",
      "episode:105 steps:5 total reward:-1.08 epsilon:0.3516092065580223\n",
      "episode:106 steps:8 total reward:-1.1400000000000001 epsilon:0.34809311449244207\n",
      "episode:107 steps:13 total reward:0.76 epsilon:0.34461218334751764\n",
      "episode:108 steps:4 total reward:-1.06 epsilon:0.34116606151404244\n",
      "episode:109 steps:3 total reward:-1.04 epsilon:0.337754400898902\n",
      "episode:110 steps:4 total reward:-1.06 epsilon:0.334376856889913\n",
      "episode:111 steps:7 total reward:0.88 epsilon:0.33103308832101386\n",
      "episode:112 steps:5 total reward:-1.08 epsilon:0.3277227574378037\n",
      "episode:113 steps:26 total reward:-1.5 epsilon:0.3244455298634257\n",
      "episode:114 steps:19 total reward:0.6399999999999999 epsilon:0.3212010745647914\n",
      "episode:115 steps:12 total reward:-1.22 epsilon:0.3179890638191435\n",
      "episode:116 steps:16 total reward:-1.3 epsilon:0.31480917318095203\n",
      "episode:117 steps:16 total reward:-1.3 epsilon:0.3116610814491425\n",
      "episode:118 steps:14 total reward:-1.26 epsilon:0.30854447063465107\n",
      "episode:119 steps:6 total reward:-1.1 epsilon:0.30545902592830454\n",
      "episode:120 steps:14 total reward:0.74 epsilon:0.3024044356690215\n",
      "episode:121 steps:10 total reward:-1.18 epsilon:0.29938039131233124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-15 09:03:20,495] Starting new video recorder writing to C:\\Users\\abjilani\\Desktop\\Projects\\DL Nanodegree\\my-experiments\\reinforcement learning\\monitor\\openaigym.video.3.17488.video000125.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:122 steps:28 total reward:-1.54 epsilon:0.2963865873992079\n",
      "episode:123 steps:13 total reward:-1.24 epsilon:0.29342272152521587\n",
      "episode:124 steps:13 total reward:-1.24 epsilon:0.2904884943099637\n",
      "episode:125 steps:12 total reward:-1.22 epsilon:0.28758360936686406\n",
      "episode:126 steps:9 total reward:-1.16 epsilon:0.2847077732731954\n",
      "episode:127 steps:8 total reward:-1.1400000000000001 epsilon:0.28186069554046345\n",
      "episode:128 steps:17 total reward:-1.32 epsilon:0.2790420885850588\n",
      "episode:129 steps:8 total reward:-1.1400000000000001 epsilon:0.2762516676992082\n",
      "episode:130 steps:19 total reward:-1.36 epsilon:0.27348915102221616\n",
      "episode:131 steps:46 total reward:-1.9000000000000004 epsilon:0.270754259511994\n",
      "episode:132 steps:20 total reward:-1.3800000000000001 epsilon:0.26804671691687404\n",
      "episode:133 steps:34 total reward:-1.6600000000000001 epsilon:0.2653662497477053\n",
      "episode:134 steps:16 total reward:-1.3 epsilon:0.2627125872502282\n",
      "episode:135 steps:24 total reward:0.5399999999999998 epsilon:0.2600854613777259\n",
      "episode:136 steps:47 total reward:-1.9200000000000004 epsilon:0.2574846067639487\n",
      "episode:137 steps:34 total reward:-1.6600000000000001 epsilon:0.2549097606963092\n",
      "episode:138 steps:49 total reward:-1.9600000000000004 epsilon:0.2523606630893461\n",
      "episode:139 steps:37 total reward:-1.7200000000000002 epsilon:0.24983705645845267\n",
      "episode:140 steps:5 total reward:-1.08 epsilon:0.24733868589386815\n",
      "episode:141 steps:2 total reward:-1.02 epsilon:0.24486529903492946\n",
      "episode:142 steps:16 total reward:-1.3 epsilon:0.24241664604458016\n",
      "episode:143 steps:6 total reward:-1.1 epsilon:0.23999247958413436\n",
      "episode:144 steps:7 total reward:-1.12 epsilon:0.23759255478829303\n",
      "episode:145 steps:16 total reward:-1.3 epsilon:0.2352166292404101\n",
      "episode:146 steps:18 total reward:-1.34 epsilon:0.232864462948006\n",
      "episode:147 steps:10 total reward:-1.18 epsilon:0.23053581831852593\n",
      "episode:148 steps:26 total reward:-1.5 epsilon:0.22823046013534068\n",
      "episode:149 steps:16 total reward:-1.3 epsilon:0.22594815553398728\n",
      "episode:150 steps:26 total reward:-1.5 epsilon:0.22368867397864742\n",
      "episode:151 steps:27 total reward:-1.52 epsilon:0.22145178723886094\n",
      "episode:152 steps:9 total reward:-1.16 epsilon:0.21923726936647234\n",
      "episode:153 steps:22 total reward:-1.4200000000000002 epsilon:0.2170448966728076\n",
      "episode:154 steps:58 total reward:-2.1400000000000006 epsilon:0.21487444770607952\n",
      "episode:155 steps:18 total reward:-1.34 epsilon:0.21272570322901874\n",
      "episode:156 steps:14 total reward:-1.26 epsilon:0.21059844619672854\n",
      "episode:157 steps:12 total reward:0.78 epsilon:0.20849246173476127\n",
      "episode:158 steps:48 total reward:-1.9400000000000004 epsilon:0.20640753711741366\n",
      "episode:159 steps:9 total reward:-1.16 epsilon:0.20434346174623952\n",
      "episode:160 steps:13 total reward:-1.24 epsilon:0.20230002712877712\n",
      "episode:161 steps:9 total reward:-1.16 epsilon:0.20027702685748935\n",
      "episode:162 steps:24 total reward:-1.4600000000000002 epsilon:0.19827425658891445\n",
      "episode:163 steps:7 total reward:-1.12 epsilon:0.1962915140230253\n",
      "episode:164 steps:29 total reward:-1.56 epsilon:0.19432859888279505\n",
      "episode:165 steps:29 total reward:-1.56 epsilon:0.1923853128939671\n",
      "episode:166 steps:5 total reward:-1.08 epsilon:0.19046145976502743\n",
      "episode:167 steps:13 total reward:-1.24 epsilon:0.18855684516737714\n",
      "episode:168 steps:23 total reward:0.5599999999999998 epsilon:0.18667127671570335\n",
      "episode:169 steps:9 total reward:0.84 epsilon:0.18480456394854633\n",
      "episode:170 steps:7 total reward:-1.12 epsilon:0.18295651830906087\n",
      "episode:171 steps:19 total reward:0.6399999999999999 epsilon:0.18112695312597027\n",
      "episode:172 steps:21 total reward:-1.4000000000000001 epsilon:0.17931568359471056\n",
      "episode:173 steps:8 total reward:-1.1400000000000001 epsilon:0.17752252675876345\n",
      "episode:174 steps:91 total reward:-2.800000000000001 epsilon:0.17574730149117582\n",
      "episode:175 steps:13 total reward:-1.24 epsilon:0.17398982847626407\n",
      "episode:176 steps:44 total reward:0.13999999999999957 epsilon:0.17224993019150142\n",
      "episode:177 steps:9 total reward:-1.16 epsilon:0.1705274308895864\n",
      "episode:178 steps:10 total reward:-1.18 epsilon:0.16882215658069055\n",
      "episode:179 steps:19 total reward:-1.36 epsilon:0.16713393501488363\n",
      "episode:180 steps:21 total reward:-1.4000000000000001 epsilon:0.16546259566473479\n",
      "episode:181 steps:16 total reward:-1.3 epsilon:0.16380796970808745\n",
      "episode:182 steps:6 total reward:-1.1 epsilon:0.16216989001100657\n",
      "episode:183 steps:55 total reward:-2.0800000000000005 epsilon:0.1605481911108965\n",
      "episode:184 steps:22 total reward:-1.4200000000000002 epsilon:0.15894270919978754\n",
      "episode:185 steps:22 total reward:-1.4200000000000002 epsilon:0.15735328210778965\n",
      "episode:186 steps:4 total reward:-1.06 epsilon:0.15577974928671176\n",
      "episode:187 steps:100 total reward:-2.9800000000000013 epsilon:0.15422195179384465\n",
      "episode:188 steps:9 total reward:-1.16 epsilon:0.1526797322759062\n",
      "episode:189 steps:23 total reward:-1.4400000000000002 epsilon:0.15115293495314713\n",
      "episode:190 steps:54 total reward:-2.0600000000000005 epsilon:0.14964140560361566\n",
      "episode:191 steps:17 total reward:-1.32 epsilon:0.1481449915475795\n",
      "episode:192 steps:40 total reward:-1.7800000000000002 epsilon:0.1466635416321037\n",
      "episode:193 steps:9 total reward:-1.16 epsilon:0.14519690621578268\n",
      "episode:194 steps:6 total reward:-1.1 epsilon:0.14374493715362485\n",
      "episode:195 steps:16 total reward:0.7 epsilon:0.1423074877820886\n",
      "episode:196 steps:47 total reward:0.07999999999999952 epsilon:0.1408844129042677\n",
      "episode:197 steps:5 total reward:-1.08 epsilon:0.13947556877522502\n",
      "episode:198 steps:7 total reward:-1.12 epsilon:0.13808081308747278\n",
      "episode:199 steps:18 total reward:-1.34 epsilon:0.13670000495659804\n",
      "episode:200 steps:11 total reward:-1.2 epsilon:0.13533300490703207\n",
      "episode:201 steps:20 total reward:-1.3800000000000001 epsilon:0.13397967485796175\n",
      "episode:202 steps:19 total reward:0.6399999999999999 epsilon:0.13263987810938213\n",
      "episode:203 steps:8 total reward:-1.1400000000000001 epsilon:0.1313134793282883\n",
      "episode:204 steps:2 total reward:-1.02 epsilon:0.13000034453500542\n",
      "episode:205 steps:81 total reward:-2.600000000000001 epsilon:0.12870034108965536\n",
      "episode:206 steps:10 total reward:-1.18 epsilon:0.12741333767875881\n",
      "episode:207 steps:7 total reward:-1.12 epsilon:0.12613920430197123\n",
      "episode:208 steps:45 total reward:-1.8800000000000003 epsilon:0.12487781225895152\n",
      "episode:209 steps:32 total reward:-1.62 epsilon:0.123629034136362\n",
      "episode:210 steps:39 total reward:-1.7600000000000002 epsilon:0.12239274379499838\n",
      "episode:211 steps:39 total reward:-1.7600000000000002 epsilon:0.1211688163570484\n",
      "episode:212 steps:100 total reward:-2.9800000000000013 epsilon:0.11995712819347792\n",
      "episode:213 steps:5 total reward:-1.08 epsilon:0.11875755691154315\n",
      "episode:214 steps:100 total reward:-2.9800000000000013 epsilon:0.11756998134242772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-15 09:03:35,948] Starting new video recorder writing to C:\\Users\\abjilani\\Desktop\\Projects\\DL Nanodegree\\my-experiments\\reinforcement learning\\monitor\\openaigym.video.3.17488.video000216.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:215 steps:100 total reward:-2.9800000000000013 epsilon:0.11639428152900344\n",
      "episode:216 steps:26 total reward:-1.5 epsilon:0.11523033871371341\n",
      "episode:217 steps:10 total reward:-1.18 epsilon:0.11407803532657627\n",
      "episode:218 steps:11 total reward:-1.2 epsilon:0.11293725497331052\n",
      "episode:219 steps:7 total reward:-1.12 epsilon:0.1118078824235774\n",
      "episode:220 steps:6 total reward:-1.1 epsilon:0.11068980359934164\n",
      "episode:221 steps:18 total reward:-1.34 epsilon:0.10958290556334822\n",
      "episode:222 steps:25 total reward:0.5199999999999998 epsilon:0.10848707650771475\n",
      "episode:223 steps:26 total reward:0.4999999999999999 epsilon:0.1074022057426376\n",
      "episode:224 steps:75 total reward:-2.480000000000001 epsilon:0.10632818368521123\n",
      "episode:225 steps:23 total reward:-1.4400000000000002 epsilon:0.10526490184835911\n",
      "episode:226 steps:59 total reward:-2.1600000000000006 epsilon:0.10421225282987552\n",
      "episode:227 steps:22 total reward:-1.4200000000000002 epsilon:0.10317013030157676\n",
      "episode:228 steps:6 total reward:-1.1 epsilon:0.10213842899856099\n",
      "episode:229 steps:29 total reward:0.43999999999999984 epsilon:0.10111704470857538\n",
      "episode:230 steps:20 total reward:0.6199999999999999 epsilon:0.10010587426148963\n",
      "episode:231 steps:20 total reward:0.6199999999999999 epsilon:0.09910481551887473\n",
      "episode:232 steps:87 total reward:-2.720000000000001 epsilon:0.09811376736368599\n",
      "episode:233 steps:25 total reward:0.5199999999999998 epsilon:0.09713262969004913\n",
      "episode:234 steps:9 total reward:-1.16 epsilon:0.09616130339314863\n",
      "episode:235 steps:33 total reward:0.35999999999999976 epsilon:0.09519969035921715\n",
      "episode:236 steps:13 total reward:0.76 epsilon:0.09424769345562498\n",
      "episode:237 steps:15 total reward:-1.28 epsilon:0.09330521652106873\n",
      "episode:238 steps:47 total reward:0.07999999999999952 epsilon:0.09237216435585804\n",
      "episode:239 steps:8 total reward:-1.1400000000000001 epsilon:0.09144844271229946\n",
      "episode:240 steps:100 total reward:-2.9800000000000013 epsilon:0.09053395828517646\n",
      "episode:241 steps:19 total reward:0.6399999999999999 epsilon:0.08962861870232469\n",
      "episode:242 steps:11 total reward:0.8 epsilon:0.08873233251530144\n",
      "episode:243 steps:35 total reward:0.31999999999999973 epsilon:0.08784500919014843\n",
      "episode:244 steps:10 total reward:-1.18 epsilon:0.08696655909824694\n",
      "episode:245 steps:26 total reward:-1.5 epsilon:0.08609689350726446\n",
      "episode:246 steps:23 total reward:-1.4400000000000002 epsilon:0.08523592457219181\n",
      "episode:247 steps:22 total reward:-1.4200000000000002 epsilon:0.0843835653264699\n",
      "episode:248 steps:25 total reward:-1.4800000000000002 epsilon:0.0835397296732052\n",
      "episode:249 steps:74 total reward:-2.460000000000001 epsilon:0.08270433237647315\n",
      "episode:250 steps:8 total reward:0.86 epsilon:0.08187728905270841\n",
      "episode:251 steps:28 total reward:-1.54 epsilon:0.08105851616218133\n",
      "episode:252 steps:81 total reward:-0.600000000000001 epsilon:0.08024793100055952\n",
      "episode:253 steps:29 total reward:-1.56 epsilon:0.07944545169055392\n",
      "episode:254 steps:8 total reward:-1.1400000000000001 epsilon:0.07865099717364837\n",
      "episode:255 steps:38 total reward:-1.7400000000000002 epsilon:0.07786448720191189\n",
      "episode:256 steps:43 total reward:0.1599999999999996 epsilon:0.07708584232989277\n",
      "episode:257 steps:15 total reward:0.72 epsilon:0.07631498390659384\n",
      "episode:258 steps:38 total reward:-1.7400000000000002 epsilon:0.07555183406752791\n",
      "episode:259 steps:7 total reward:-1.12 epsilon:0.07479631572685264\n",
      "episode:260 steps:100 total reward:-2.9800000000000013 epsilon:0.07404835256958411\n",
      "episode:261 steps:13 total reward:-1.24 epsilon:0.07330786904388827\n",
      "episode:262 steps:46 total reward:-1.9000000000000004 epsilon:0.07257479035344938\n",
      "episode:263 steps:37 total reward:-1.7200000000000002 epsilon:0.07184904244991488\n",
      "episode:264 steps:18 total reward:-1.34 epsilon:0.07113055202541574\n",
      "episode:265 steps:41 total reward:-1.8000000000000003 epsilon:0.07041924650516158\n",
      "episode:266 steps:13 total reward:-1.24 epsilon:0.06971505404010997\n",
      "episode:267 steps:2 total reward:-1.02 epsilon:0.06901790349970886\n",
      "episode:268 steps:24 total reward:-1.4600000000000002 epsilon:0.06832772446471178\n",
      "episode:269 steps:35 total reward:-1.6800000000000002 epsilon:0.06764444722006466\n",
      "episode:270 steps:55 total reward:-0.08000000000000052 epsilon:0.066968002747864\n",
      "episode:271 steps:41 total reward:-1.8000000000000003 epsilon:0.06629832272038537\n",
      "episode:272 steps:38 total reward:0.2599999999999997 epsilon:0.06563533949318151\n",
      "episode:273 steps:17 total reward:-1.32 epsilon:0.06497898609824969\n",
      "episode:274 steps:100 total reward:-2.9800000000000013 epsilon:0.0643291962372672\n",
      "episode:275 steps:72 total reward:-0.4200000000000008 epsilon:0.06368590427489453\n",
      "episode:276 steps:22 total reward:-1.4200000000000002 epsilon:0.06304904523214558\n",
      "episode:277 steps:16 total reward:-1.3 epsilon:0.06241855477982412\n",
      "episode:278 steps:21 total reward:-1.4000000000000001 epsilon:0.06179436923202588\n",
      "episode:279 steps:34 total reward:-1.6600000000000001 epsilon:0.06117642553970562\n",
      "episode:280 steps:100 total reward:-2.9800000000000013 epsilon:0.06056466128430856\n",
      "episode:281 steps:59 total reward:-2.1600000000000006 epsilon:0.05995901467146548\n",
      "episode:282 steps:39 total reward:-1.7600000000000002 epsilon:0.05935942452475082\n",
      "episode:283 steps:84 total reward:-2.660000000000001 epsilon:0.058765830279503314\n",
      "episode:284 steps:18 total reward:-1.34 epsilon:0.05817817197670828\n",
      "episode:285 steps:24 total reward:0.5399999999999998 epsilon:0.057596390256941195\n",
      "episode:286 steps:17 total reward:-1.32 epsilon:0.05702042635437178\n",
      "episode:287 steps:45 total reward:-1.8800000000000003 epsilon:0.05645022209082806\n",
      "episode:288 steps:100 total reward:-2.9800000000000013 epsilon:0.05588571986991978\n",
      "episode:289 steps:18 total reward:-1.34 epsilon:0.055326862671220584\n",
      "episode:290 steps:25 total reward:-1.4800000000000002 epsilon:0.05477359404450838\n",
      "episode:291 steps:100 total reward:-2.9800000000000013 epsilon:0.054225858104063294\n",
      "episode:292 steps:46 total reward:0.09999999999999953 epsilon:0.05368359952302266\n",
      "episode:293 steps:36 total reward:-1.7000000000000002 epsilon:0.053146763527792434\n",
      "episode:294 steps:45 total reward:-1.8800000000000003 epsilon:0.052615295892514506\n",
      "episode:295 steps:46 total reward:0.09999999999999953 epsilon:0.052089142933589364\n",
      "episode:296 steps:25 total reward:0.5199999999999998 epsilon:0.05156825150425347\n",
      "episode:297 steps:100 total reward:-2.9800000000000013 epsilon:0.051052568989210935\n",
      "episode:298 steps:10 total reward:0.8200000000000001 epsilon:0.05054204329931883\n",
      "episode:299 steps:11 total reward:-1.2 epsilon:0.05003662286632564\n",
      "episode:300 steps:15 total reward:-1.28 epsilon:0.04953625663766238\n",
      "episode:301 steps:20 total reward:0.6199999999999999 epsilon:0.04904089407128576\n",
      "episode:302 steps:47 total reward:-1.9200000000000004 epsilon:0.0485504851305729\n",
      "episode:303 steps:14 total reward:-1.26 epsilon:0.048064980279267165\n",
      "episode:304 steps:6 total reward:-1.1 epsilon:0.04758433047647449\n",
      "episode:305 steps:28 total reward:-1.54 epsilon:0.04710848717170975\n",
      "episode:306 steps:25 total reward:0.5199999999999998 epsilon:0.04663740229999265\n",
      "episode:307 steps:15 total reward:-1.28 epsilon:0.04617102827699272\n",
      "episode:308 steps:100 total reward:-2.9800000000000013 epsilon:0.045709317994222794\n",
      "episode:309 steps:24 total reward:-1.4600000000000002 epsilon:0.04525222481428057\n",
      "episode:310 steps:4 total reward:-1.06 epsilon:0.04479970256613776\n",
      "episode:311 steps:49 total reward:0.03999999999999948 epsilon:0.04435170554047638\n",
      "episode:312 steps:36 total reward:-1.7000000000000002 epsilon:0.043908188485071616\n",
      "episode:313 steps:14 total reward:0.74 epsilon:0.0434691066002209\n",
      "episode:314 steps:29 total reward:-1.56 epsilon:0.04303441553421869\n",
      "episode:315 steps:66 total reward:-2.3000000000000007 epsilon:0.0426040713788765\n",
      "episode:316 steps:28 total reward:0.45999999999999985 epsilon:0.04217803066508773\n",
      "episode:317 steps:26 total reward:-1.5 epsilon:0.04175625035843686\n",
      "episode:318 steps:27 total reward:-1.52 epsilon:0.041338687854852486\n",
      "episode:319 steps:29 total reward:-1.56 epsilon:0.04092530097630396\n",
      "episode:320 steps:23 total reward:-1.4400000000000002 epsilon:0.040516047966540916\n",
      "episode:321 steps:18 total reward:-1.34 epsilon:0.04011088748687551\n",
      "episode:322 steps:25 total reward:0.5199999999999998 epsilon:0.03970977861200675\n",
      "episode:323 steps:10 total reward:-1.18 epsilon:0.03931268082588668\n",
      "episode:324 steps:24 total reward:0.5399999999999998 epsilon:0.03891955401762781\n",
      "episode:325 steps:51 total reward:-2.0000000000000004 epsilon:0.03853035847745153\n",
      "episode:326 steps:11 total reward:0.8 epsilon:0.03814505489267701\n",
      "episode:327 steps:20 total reward:0.6199999999999999 epsilon:0.03776360434375024\n",
      "episode:328 steps:32 total reward:-1.62 epsilon:0.03738596830031274\n",
      "episode:329 steps:6 total reward:-1.1 epsilon:0.03701210861730961\n",
      "episode:330 steps:12 total reward:-1.22 epsilon:0.03664198753113651\n",
      "episode:331 steps:5 total reward:-1.08 epsilon:0.036275567655825146\n",
      "episode:332 steps:14 total reward:0.74 epsilon:0.03591281197926689\n",
      "episode:333 steps:32 total reward:0.3799999999999998 epsilon:0.035553683859474224\n",
      "episode:334 steps:38 total reward:0.2599999999999997 epsilon:0.03519814702087948\n",
      "episode:335 steps:50 total reward:0.019999999999999463 epsilon:0.03484616555067068\n",
      "episode:336 steps:62 total reward:-2.2200000000000006 epsilon:0.034497703895163975\n",
      "episode:337 steps:41 total reward:0.19999999999999962 epsilon:0.03415272685621234\n",
      "episode:338 steps:46 total reward:-1.9000000000000004 epsilon:0.03381119958765021\n",
      "episode:339 steps:43 total reward:-1.8400000000000003 epsilon:0.03347308759177371\n",
      "episode:340 steps:30 total reward:0.4199999999999998 epsilon:0.03313835671585597\n",
      "episode:341 steps:26 total reward:0.4999999999999999 epsilon:0.03280697314869741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-15 09:04:04,906] Starting new video recorder writing to C:\\Users\\abjilani\\Desktop\\Projects\\DL Nanodegree\\my-experiments\\reinforcement learning\\monitor\\openaigym.video.3.17488.video000343.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:342 steps:30 total reward:0.4199999999999998 epsilon:0.032478903417210436\n",
      "episode:343 steps:43 total reward:0.1599999999999996 epsilon:0.032154114383038335\n",
      "episode:344 steps:34 total reward:-1.6600000000000001 epsilon:0.03183257323920795\n",
      "episode:345 steps:40 total reward:-1.7800000000000002 epsilon:0.03151424750681587\n",
      "episode:346 steps:100 total reward:-2.9800000000000013 epsilon:0.03119910503174771\n",
      "episode:347 steps:14 total reward:0.74 epsilon:0.030887113981430233\n",
      "episode:348 steps:56 total reward:-2.1000000000000005 epsilon:0.03057824284161593\n",
      "episode:349 steps:100 total reward:-2.9800000000000013 epsilon:0.03027246041319977\n",
      "episode:350 steps:85 total reward:-2.680000000000001 epsilon:0.029969735809067772\n",
      "episode:351 steps:20 total reward:-1.3800000000000001 epsilon:0.029670038450977095\n",
      "episode:352 steps:27 total reward:-1.52 epsilon:0.029373338066467324\n",
      "episode:353 steps:37 total reward:-1.7200000000000002 epsilon:0.02907960468580265\n",
      "episode:354 steps:8 total reward:-1.1400000000000001 epsilon:0.028788808638944622\n",
      "episode:355 steps:2 total reward:-1.02 epsilon:0.028500920552555174\n",
      "episode:356 steps:36 total reward:-1.7000000000000002 epsilon:0.028215911347029624\n",
      "episode:357 steps:13 total reward:-1.24 epsilon:0.027933752233559327\n",
      "episode:358 steps:100 total reward:-2.9800000000000013 epsilon:0.027654414711223735\n",
      "episode:359 steps:64 total reward:-2.2600000000000007 epsilon:0.027377870564111496\n",
      "episode:360 steps:15 total reward:-1.28 epsilon:0.027104091858470382\n",
      "episode:361 steps:15 total reward:-1.28 epsilon:0.026833050939885677\n",
      "episode:362 steps:40 total reward:-1.7800000000000002 epsilon:0.02656472043048682\n",
      "episode:363 steps:7 total reward:-1.12 epsilon:0.02629907322618195\n",
      "episode:364 steps:10 total reward:-1.18 epsilon:0.026036082493920133\n",
      "episode:365 steps:9 total reward:-1.16 epsilon:0.02577572166898093\n",
      "episode:366 steps:18 total reward:-1.34 epsilon:0.025517964452291122\n",
      "episode:367 steps:8 total reward:-1.1400000000000001 epsilon:0.02526278480776821\n",
      "episode:368 steps:9 total reward:-1.16 epsilon:0.025010156959690527\n",
      "episode:369 steps:6 total reward:-1.1 epsilon:0.02476005539009362\n",
      "episode:370 steps:13 total reward:-1.24 epsilon:0.024512454836192684\n",
      "episode:371 steps:78 total reward:-2.540000000000001 epsilon:0.024267330287830756\n",
      "episode:372 steps:6 total reward:-1.1 epsilon:0.024024656984952448\n",
      "episode:373 steps:73 total reward:-2.440000000000001 epsilon:0.023784410415102923\n",
      "episode:374 steps:28 total reward:0.45999999999999985 epsilon:0.023546566310951894\n",
      "episode:375 steps:27 total reward:-1.52 epsilon:0.023311100647842375\n",
      "episode:376 steps:48 total reward:0.0599999999999995 epsilon:0.02307798964136395\n",
      "episode:377 steps:75 total reward:-0.48000000000000087 epsilon:0.022847209744950314\n",
      "episode:378 steps:15 total reward:-1.28 epsilon:0.02261873764750081\n",
      "episode:379 steps:100 total reward:-2.9800000000000013 epsilon:0.022392550271025803\n",
      "episode:380 steps:12 total reward:-1.22 epsilon:0.022168624768315544\n",
      "episode:381 steps:100 total reward:-2.9800000000000013 epsilon:0.02194693852063239\n",
      "episode:382 steps:31 total reward:0.3999999999999998 epsilon:0.021727469135426065\n",
      "episode:383 steps:88 total reward:-2.740000000000001 epsilon:0.021510194444071803\n",
      "episode:384 steps:16 total reward:0.7 epsilon:0.021295092499631085\n",
      "episode:385 steps:34 total reward:-1.6600000000000001 epsilon:0.021082141574634772\n",
      "episode:386 steps:42 total reward:-1.8200000000000003 epsilon:0.020871320158888425\n",
      "episode:387 steps:8 total reward:-1.1400000000000001 epsilon:0.020662606957299542\n",
      "episode:388 steps:66 total reward:-0.3000000000000007 epsilon:0.020455980887726547\n",
      "episode:389 steps:19 total reward:0.6399999999999999 epsilon:0.02025142107884928\n",
      "episode:390 steps:10 total reward:-1.18 epsilon:0.020048906868060788\n",
      "episode:391 steps:64 total reward:-2.2600000000000007 epsilon:0.01984841779938018\n",
      "episode:392 steps:37 total reward:-1.7200000000000002 epsilon:0.019649933621386378\n",
      "episode:393 steps:62 total reward:-2.2200000000000006 epsilon:0.019453434285172513\n",
      "episode:394 steps:36 total reward:-1.7000000000000002 epsilon:0.019258899942320787\n",
      "episode:395 steps:100 total reward:-2.9800000000000013 epsilon:0.01906631094289758\n",
      "episode:396 steps:19 total reward:-1.36 epsilon:0.018875647833468602\n",
      "episode:397 steps:30 total reward:-1.58 epsilon:0.018686891355133916\n",
      "episode:398 steps:13 total reward:0.76 epsilon:0.018500022441582577\n",
      "episode:399 steps:72 total reward:-0.4200000000000008 epsilon:0.01831502221716675\n",
      "episode:400 steps:84 total reward:-0.660000000000001 epsilon:0.018131871994995084\n",
      "episode:401 steps:16 total reward:0.7 epsilon:0.017950553275045134\n",
      "episode:402 steps:43 total reward:0.1599999999999996 epsilon:0.017771047742294682\n",
      "episode:403 steps:100 total reward:-2.9800000000000013 epsilon:0.017593337264871736\n",
      "episode:404 steps:35 total reward:0.31999999999999973 epsilon:0.01741740389222302\n",
      "episode:405 steps:21 total reward:-1.4000000000000001 epsilon:0.01724322985330079\n",
      "episode:406 steps:9 total reward:0.84 epsilon:0.017070797554767782\n",
      "episode:407 steps:73 total reward:-0.44000000000000083 epsilon:0.016900089579220106\n",
      "episode:408 steps:58 total reward:-0.14000000000000057 epsilon:0.016731088683427906\n",
      "episode:409 steps:14 total reward:0.74 epsilon:0.016563777796593626\n",
      "episode:410 steps:24 total reward:-1.4600000000000002 epsilon:0.016398140018627688\n",
      "episode:411 steps:39 total reward:-1.7600000000000002 epsilon:0.01623415861844141\n",
      "episode:412 steps:62 total reward:-0.22000000000000064 epsilon:0.016071817032256998\n",
      "episode:413 steps:11 total reward:-1.2 epsilon:0.01591109886193443\n",
      "episode:414 steps:31 total reward:-1.6 epsilon:0.015751987873315085\n",
      "episode:415 steps:77 total reward:-0.5200000000000009 epsilon:0.015594467994581935\n",
      "episode:416 steps:11 total reward:-1.2 epsilon:0.015438523314636115\n",
      "episode:417 steps:24 total reward:0.5399999999999998 epsilon:0.015284138081489753\n",
      "episode:418 steps:8 total reward:0.86 epsilon:0.015131296700674856\n",
      "episode:419 steps:10 total reward:-1.18 epsilon:0.014979983733668108\n",
      "episode:420 steps:25 total reward:0.5199999999999998 epsilon:0.014830183896331426\n",
      "episode:421 steps:33 total reward:-1.6400000000000001 epsilon:0.014681882057368112\n",
      "episode:422 steps:89 total reward:-2.760000000000001 epsilon:0.01453506323679443\n",
      "episode:423 steps:6 total reward:-1.1 epsilon:0.014389712604426485\n",
      "episode:424 steps:11 total reward:-1.2 epsilon:0.01424581547838222\n",
      "episode:425 steps:52 total reward:-2.0200000000000005 epsilon:0.014103357323598397\n",
      "episode:426 steps:88 total reward:-0.7400000000000011 epsilon:0.013962323750362413\n",
      "episode:427 steps:100 total reward:-2.9800000000000013 epsilon:0.013822700512858789\n",
      "episode:428 steps:100 total reward:-2.9800000000000013 epsilon:0.0136844735077302\n",
      "episode:429 steps:17 total reward:-1.32 epsilon:0.013547628772652899\n",
      "episode:430 steps:51 total reward:-2.0000000000000004 epsilon:0.01341215248492637\n",
      "episode:431 steps:10 total reward:-1.18 epsilon:0.013278030960077106\n",
      "episode:432 steps:19 total reward:0.6399999999999999 epsilon:0.013145250650476335\n",
      "episode:433 steps:100 total reward:-2.9800000000000013 epsilon:0.01301379814397157\n",
      "episode:434 steps:50 total reward:-1.9800000000000004 epsilon:0.012883660162531854\n",
      "episode:435 steps:30 total reward:0.4199999999999998 epsilon:0.012754823560906535\n",
      "episode:436 steps:10 total reward:-1.18 epsilon:0.01262727532529747\n",
      "episode:437 steps:100 total reward:-2.9800000000000013 epsilon:0.012501002572044496\n",
      "episode:438 steps:33 total reward:-1.6400000000000001 epsilon:0.01237599254632405\n",
      "episode:439 steps:100 total reward:-2.9800000000000013 epsilon:0.01225223262086081\n",
      "episode:440 steps:100 total reward:-2.9800000000000013 epsilon:0.012129710294652202\n",
      "episode:441 steps:57 total reward:-2.1200000000000006 epsilon:0.01200841319170568\n",
      "episode:442 steps:12 total reward:-1.22 epsilon:0.011888329059788623\n",
      "episode:443 steps:58 total reward:-0.14000000000000057 epsilon:0.011769445769190737\n",
      "episode:444 steps:100 total reward:-2.9800000000000013 epsilon:0.01165175131149883\n",
      "episode:445 steps:20 total reward:-1.3800000000000001 epsilon:0.011535233798383842\n",
      "episode:446 steps:9 total reward:-1.16 epsilon:0.011419881460400004\n",
      "episode:447 steps:66 total reward:-0.3000000000000007 epsilon:0.011305682645796004\n",
      "episode:448 steps:31 total reward:-1.6 epsilon:0.011192625819338045\n",
      "episode:449 steps:40 total reward:-1.7800000000000002 epsilon:0.011080699561144665\n",
      "episode:450 steps:100 total reward:-2.9800000000000013 epsilon:0.010969892565533218\n",
      "episode:451 steps:15 total reward:-1.28 epsilon:0.010860193639877886\n",
      "episode:452 steps:94 total reward:-0.8600000000000012 epsilon:0.010751591703479106\n",
      "episode:453 steps:46 total reward:0.09999999999999953 epsilon:0.010644075786444315\n",
      "episode:454 steps:100 total reward:-2.9800000000000013 epsilon:0.010537635028579873\n",
      "episode:455 steps:99 total reward:-0.9600000000000013 epsilon:0.010432258678294073\n",
      "episode:456 steps:100 total reward:-2.9800000000000013 epsilon:0.010327936091511133\n",
      "episode:457 steps:100 total reward:-2.9800000000000013 epsilon:0.010224656730596022\n",
      "episode:458 steps:100 total reward:-2.9800000000000013 epsilon:0.01012241016329006\n",
      "episode:459 steps:11 total reward:-1.2 epsilon:0.01002118606165716\n",
      "episode:460 steps:42 total reward:0.1799999999999996 epsilon:0.009920974201040588\n",
      "episode:461 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:462 steps:72 total reward:-0.4200000000000008 epsilon:0.009920974201040588\n",
      "episode:463 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:464 steps:62 total reward:-2.2200000000000006 epsilon:0.009920974201040588\n",
      "episode:465 steps:37 total reward:-1.7200000000000002 epsilon:0.009920974201040588\n",
      "episode:466 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:467 steps:41 total reward:-1.8000000000000003 epsilon:0.009920974201040588\n",
      "episode:468 steps:9 total reward:-1.16 epsilon:0.009920974201040588\n",
      "episode:469 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:470 steps:35 total reward:-1.6800000000000002 epsilon:0.009920974201040588\n",
      "episode:471 steps:20 total reward:0.6199999999999999 epsilon:0.009920974201040588\n",
      "episode:472 steps:20 total reward:-1.3800000000000001 epsilon:0.009920974201040588\n",
      "episode:473 steps:25 total reward:-1.4800000000000002 epsilon:0.009920974201040588\n",
      "episode:474 steps:5 total reward:-1.08 epsilon:0.009920974201040588\n",
      "episode:475 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:476 steps:6 total reward:-1.1 epsilon:0.009920974201040588\n",
      "episode:477 steps:22 total reward:0.5799999999999998 epsilon:0.009920974201040588\n",
      "episode:478 steps:57 total reward:-2.1200000000000006 epsilon:0.009920974201040588\n",
      "episode:479 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:480 steps:28 total reward:-1.54 epsilon:0.009920974201040588\n",
      "episode:481 steps:10 total reward:-1.18 epsilon:0.009920974201040588\n",
      "episode:482 steps:6 total reward:-1.1 epsilon:0.009920974201040588\n",
      "episode:483 steps:17 total reward:-1.32 epsilon:0.009920974201040588\n",
      "episode:484 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:485 steps:5 total reward:-1.08 epsilon:0.009920974201040588\n",
      "episode:486 steps:59 total reward:-0.1600000000000006 epsilon:0.009920974201040588\n",
      "episode:487 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:488 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:489 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:490 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:491 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:492 steps:45 total reward:-1.8800000000000003 epsilon:0.009920974201040588\n",
      "episode:493 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:494 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:495 steps:20 total reward:-1.3800000000000001 epsilon:0.009920974201040588\n",
      "episode:496 steps:76 total reward:-2.500000000000001 epsilon:0.009920974201040588\n",
      "episode:497 steps:51 total reward:-4.440892098500626e-16 epsilon:0.009920974201040588\n",
      "episode:498 steps:12 total reward:0.78 epsilon:0.009920974201040588\n",
      "episode:499 steps:23 total reward:-1.4400000000000002 epsilon:0.009920974201040588\n",
      "episode:500 steps:43 total reward:-1.8400000000000003 epsilon:0.009920974201040588\n",
      "episode:501 steps:28 total reward:0.45999999999999985 epsilon:0.009920974201040588\n",
      "episode:502 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:503 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:504 steps:32 total reward:-1.62 epsilon:0.009920974201040588\n",
      "episode:505 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:506 steps:23 total reward:0.5599999999999998 epsilon:0.009920974201040588\n",
      "episode:507 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:508 steps:26 total reward:-1.5 epsilon:0.009920974201040588\n",
      "episode:509 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:510 steps:31 total reward:0.3999999999999998 epsilon:0.009920974201040588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-15 09:04:59,341] Starting new video recorder writing to C:\\Users\\abjilani\\Desktop\\Projects\\DL Nanodegree\\my-experiments\\reinforcement learning\\monitor\\openaigym.video.3.17488.video000512.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:511 steps:49 total reward:0.03999999999999948 epsilon:0.009920974201040588\n",
      "episode:512 steps:15 total reward:0.72 epsilon:0.009920974201040588\n",
      "episode:513 steps:11 total reward:-1.2 epsilon:0.009920974201040588\n",
      "episode:514 steps:24 total reward:0.5399999999999998 epsilon:0.009920974201040588\n",
      "episode:515 steps:13 total reward:0.76 epsilon:0.009920974201040588\n",
      "episode:516 steps:55 total reward:-2.0800000000000005 epsilon:0.009920974201040588\n",
      "episode:517 steps:12 total reward:-1.22 epsilon:0.009920974201040588\n",
      "episode:518 steps:27 total reward:0.47999999999999987 epsilon:0.009920974201040588\n",
      "episode:519 steps:10 total reward:0.8200000000000001 epsilon:0.009920974201040588\n",
      "episode:520 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:521 steps:73 total reward:-0.44000000000000083 epsilon:0.009920974201040588\n",
      "episode:522 steps:26 total reward:-1.5 epsilon:0.009920974201040588\n",
      "episode:523 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:524 steps:63 total reward:-2.2400000000000007 epsilon:0.009920974201040588\n",
      "episode:525 steps:77 total reward:-2.520000000000001 epsilon:0.009920974201040588\n",
      "episode:526 steps:7 total reward:-1.12 epsilon:0.009920974201040588\n",
      "episode:527 steps:16 total reward:-1.3 epsilon:0.009920974201040588\n",
      "episode:528 steps:28 total reward:0.45999999999999985 epsilon:0.009920974201040588\n",
      "episode:529 steps:57 total reward:-0.12000000000000055 epsilon:0.009920974201040588\n",
      "episode:530 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:531 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:532 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:533 steps:87 total reward:-0.7200000000000011 epsilon:0.009920974201040588\n",
      "episode:534 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:535 steps:58 total reward:-0.14000000000000057 epsilon:0.009920974201040588\n",
      "episode:536 steps:7 total reward:-1.12 epsilon:0.009920974201040588\n",
      "episode:537 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:538 steps:19 total reward:0.6399999999999999 epsilon:0.009920974201040588\n",
      "episode:539 steps:6 total reward:-1.1 epsilon:0.009920974201040588\n",
      "episode:540 steps:10 total reward:-1.18 epsilon:0.009920974201040588\n",
      "episode:541 steps:29 total reward:-1.56 epsilon:0.009920974201040588\n",
      "episode:542 steps:28 total reward:-1.54 epsilon:0.009920974201040588\n",
      "episode:543 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:544 steps:79 total reward:-0.5600000000000009 epsilon:0.009920974201040588\n",
      "episode:545 steps:88 total reward:-0.7400000000000011 epsilon:0.009920974201040588\n",
      "episode:546 steps:99 total reward:-0.9600000000000013 epsilon:0.009920974201040588\n",
      "episode:547 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:548 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:549 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:550 steps:28 total reward:0.45999999999999985 epsilon:0.009920974201040588\n",
      "episode:551 steps:86 total reward:-0.7000000000000011 epsilon:0.009920974201040588\n",
      "episode:552 steps:41 total reward:0.19999999999999962 epsilon:0.009920974201040588\n",
      "episode:553 steps:46 total reward:0.09999999999999953 epsilon:0.009920974201040588\n",
      "episode:554 steps:49 total reward:0.03999999999999948 epsilon:0.009920974201040588\n",
      "episode:555 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:556 steps:46 total reward:0.09999999999999953 epsilon:0.009920974201040588\n",
      "episode:557 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:558 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:559 steps:84 total reward:-0.660000000000001 epsilon:0.009920974201040588\n",
      "episode:560 steps:67 total reward:-0.32000000000000073 epsilon:0.009920974201040588\n",
      "episode:561 steps:76 total reward:-2.500000000000001 epsilon:0.009920974201040588\n",
      "episode:562 steps:57 total reward:-2.1200000000000006 epsilon:0.009920974201040588\n",
      "episode:563 steps:9 total reward:-1.16 epsilon:0.009920974201040588\n",
      "episode:564 steps:29 total reward:0.43999999999999984 epsilon:0.009920974201040588\n",
      "episode:565 steps:11 total reward:-1.2 epsilon:0.009920974201040588\n",
      "episode:566 steps:51 total reward:-4.440892098500626e-16 epsilon:0.009920974201040588\n",
      "episode:567 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:568 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:569 steps:67 total reward:-2.3200000000000007 epsilon:0.009920974201040588\n",
      "episode:570 steps:44 total reward:-1.8600000000000003 epsilon:0.009920974201040588\n",
      "episode:571 steps:25 total reward:0.5199999999999998 epsilon:0.009920974201040588\n",
      "episode:572 steps:32 total reward:0.3799999999999998 epsilon:0.009920974201040588\n",
      "episode:573 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:574 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:575 steps:70 total reward:-2.380000000000001 epsilon:0.009920974201040588\n",
      "episode:576 steps:41 total reward:-1.8000000000000003 epsilon:0.009920974201040588\n",
      "episode:577 steps:14 total reward:0.74 epsilon:0.009920974201040588\n",
      "episode:578 steps:6 total reward:-1.1 epsilon:0.009920974201040588\n",
      "episode:579 steps:72 total reward:-0.4200000000000008 epsilon:0.009920974201040588\n",
      "episode:580 steps:87 total reward:-2.720000000000001 epsilon:0.009920974201040588\n",
      "episode:581 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:582 steps:45 total reward:-1.8800000000000003 epsilon:0.009920974201040588\n",
      "episode:583 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:584 steps:96 total reward:-2.9000000000000012 epsilon:0.009920974201040588\n",
      "episode:585 steps:47 total reward:-1.9200000000000004 epsilon:0.009920974201040588\n",
      "episode:586 steps:34 total reward:0.33999999999999975 epsilon:0.009920974201040588\n",
      "episode:587 steps:28 total reward:0.45999999999999985 epsilon:0.009920974201040588\n",
      "episode:588 steps:40 total reward:0.21999999999999964 epsilon:0.009920974201040588\n",
      "episode:589 steps:18 total reward:-1.34 epsilon:0.009920974201040588\n",
      "episode:590 steps:46 total reward:-1.9000000000000004 epsilon:0.009920974201040588\n",
      "episode:591 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:592 steps:80 total reward:-2.580000000000001 epsilon:0.009920974201040588\n",
      "episode:593 steps:31 total reward:0.3999999999999998 epsilon:0.009920974201040588\n",
      "episode:594 steps:55 total reward:-2.0800000000000005 epsilon:0.009920974201040588\n",
      "episode:595 steps:40 total reward:0.21999999999999964 epsilon:0.009920974201040588\n",
      "episode:596 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:597 steps:27 total reward:0.47999999999999987 epsilon:0.009920974201040588\n",
      "episode:598 steps:6 total reward:0.9 epsilon:0.009920974201040588\n",
      "episode:599 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:600 steps:72 total reward:-0.4200000000000008 epsilon:0.009920974201040588\n",
      "episode:601 steps:30 total reward:0.4199999999999998 epsilon:0.009920974201040588\n",
      "episode:602 steps:60 total reward:-2.1800000000000006 epsilon:0.009920974201040588\n",
      "episode:603 steps:11 total reward:-1.2 epsilon:0.009920974201040588\n",
      "episode:604 steps:20 total reward:-1.3800000000000001 epsilon:0.009920974201040588\n",
      "episode:605 steps:44 total reward:0.13999999999999957 epsilon:0.009920974201040588\n",
      "episode:606 steps:34 total reward:0.33999999999999975 epsilon:0.009920974201040588\n",
      "episode:607 steps:98 total reward:-0.9400000000000013 epsilon:0.009920974201040588\n",
      "episode:608 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:609 steps:72 total reward:-0.4200000000000008 epsilon:0.009920974201040588\n",
      "episode:610 steps:72 total reward:-0.4200000000000008 epsilon:0.009920974201040588\n",
      "episode:611 steps:41 total reward:-1.8000000000000003 epsilon:0.009920974201040588\n",
      "episode:612 steps:31 total reward:-1.6 epsilon:0.009920974201040588\n",
      "episode:613 steps:16 total reward:0.7 epsilon:0.009920974201040588\n",
      "episode:614 steps:84 total reward:-2.660000000000001 epsilon:0.009920974201040588\n",
      "episode:615 steps:9 total reward:-1.16 epsilon:0.009920974201040588\n",
      "episode:616 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:617 steps:9 total reward:0.84 epsilon:0.009920974201040588\n",
      "episode:618 steps:7 total reward:-1.12 epsilon:0.009920974201040588\n",
      "episode:619 steps:82 total reward:-0.620000000000001 epsilon:0.009920974201040588\n",
      "episode:620 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:621 steps:14 total reward:0.74 epsilon:0.009920974201040588\n",
      "episode:622 steps:58 total reward:-0.14000000000000057 epsilon:0.009920974201040588\n",
      "episode:623 steps:44 total reward:0.13999999999999957 epsilon:0.009920974201040588\n",
      "episode:624 steps:29 total reward:0.43999999999999984 epsilon:0.009920974201040588\n",
      "episode:625 steps:66 total reward:-2.3000000000000007 epsilon:0.009920974201040588\n",
      "episode:626 steps:79 total reward:-2.560000000000001 epsilon:0.009920974201040588\n",
      "episode:627 steps:14 total reward:-1.26 epsilon:0.009920974201040588\n",
      "episode:628 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:629 steps:7 total reward:-1.12 epsilon:0.009920974201040588\n",
      "episode:630 steps:17 total reward:-1.32 epsilon:0.009920974201040588\n",
      "episode:631 steps:17 total reward:0.6799999999999999 epsilon:0.009920974201040588\n",
      "episode:632 steps:43 total reward:0.1599999999999996 epsilon:0.009920974201040588\n",
      "episode:633 steps:65 total reward:-0.2800000000000007 epsilon:0.009920974201040588\n",
      "episode:634 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:635 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:636 steps:54 total reward:-0.0600000000000005 epsilon:0.009920974201040588\n",
      "episode:637 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:638 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:639 steps:93 total reward:-2.840000000000001 epsilon:0.009920974201040588\n",
      "episode:640 steps:65 total reward:-2.2800000000000007 epsilon:0.009920974201040588\n",
      "episode:641 steps:8 total reward:0.86 epsilon:0.009920974201040588\n",
      "episode:642 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:643 steps:78 total reward:-2.540000000000001 epsilon:0.009920974201040588\n",
      "episode:644 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:645 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:646 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:647 steps:15 total reward:0.72 epsilon:0.009920974201040588\n",
      "episode:648 steps:53 total reward:-0.04000000000000048 epsilon:0.009920974201040588\n",
      "episode:649 steps:11 total reward:0.8 epsilon:0.009920974201040588\n",
      "episode:650 steps:90 total reward:-2.780000000000001 epsilon:0.009920974201040588\n",
      "episode:651 steps:45 total reward:0.11999999999999955 epsilon:0.009920974201040588\n",
      "episode:652 steps:82 total reward:-0.620000000000001 epsilon:0.009920974201040588\n",
      "episode:653 steps:63 total reward:-0.24000000000000066 epsilon:0.009920974201040588\n",
      "episode:654 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:655 steps:36 total reward:-1.7000000000000002 epsilon:0.009920974201040588\n",
      "episode:656 steps:5 total reward:-1.08 epsilon:0.009920974201040588\n",
      "episode:657 steps:18 total reward:-1.34 epsilon:0.009920974201040588\n",
      "episode:658 steps:15 total reward:-1.28 epsilon:0.009920974201040588\n",
      "episode:659 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:660 steps:98 total reward:-0.9400000000000013 epsilon:0.009920974201040588\n",
      "episode:661 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:662 steps:65 total reward:-0.2800000000000007 epsilon:0.009920974201040588\n",
      "episode:663 steps:88 total reward:-0.7400000000000011 epsilon:0.009920974201040588\n",
      "episode:664 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:665 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:666 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:667 steps:65 total reward:-2.2800000000000007 epsilon:0.009920974201040588\n",
      "episode:668 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:669 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:670 steps:23 total reward:-1.4400000000000002 epsilon:0.009920974201040588\n",
      "episode:671 steps:12 total reward:0.78 epsilon:0.009920974201040588\n",
      "episode:672 steps:76 total reward:-0.5000000000000009 epsilon:0.009920974201040588\n",
      "episode:673 steps:25 total reward:-1.4800000000000002 epsilon:0.009920974201040588\n",
      "episode:674 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:675 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:676 steps:36 total reward:0.2999999999999997 epsilon:0.009920974201040588\n",
      "episode:677 steps:62 total reward:-0.22000000000000064 epsilon:0.009920974201040588\n",
      "episode:678 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:679 steps:27 total reward:0.47999999999999987 epsilon:0.009920974201040588\n",
      "episode:680 steps:22 total reward:0.5799999999999998 epsilon:0.009920974201040588\n",
      "episode:681 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:682 steps:92 total reward:-2.820000000000001 epsilon:0.009920974201040588\n",
      "episode:683 steps:35 total reward:0.31999999999999973 epsilon:0.009920974201040588\n",
      "episode:684 steps:42 total reward:-1.8200000000000003 epsilon:0.009920974201040588\n",
      "episode:685 steps:68 total reward:-2.3400000000000007 epsilon:0.009920974201040588\n",
      "episode:686 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:687 steps:90 total reward:-0.7800000000000011 epsilon:0.009920974201040588\n",
      "episode:688 steps:9 total reward:0.84 epsilon:0.009920974201040588\n",
      "episode:689 steps:88 total reward:-0.7400000000000011 epsilon:0.009920974201040588\n",
      "episode:690 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:691 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:692 steps:27 total reward:-1.52 epsilon:0.009920974201040588\n",
      "episode:693 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:694 steps:27 total reward:0.47999999999999987 epsilon:0.009920974201040588\n",
      "episode:695 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:696 steps:28 total reward:0.45999999999999985 epsilon:0.009920974201040588\n",
      "episode:697 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:698 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:699 steps:13 total reward:0.76 epsilon:0.009920974201040588\n",
      "episode:700 steps:91 total reward:-2.800000000000001 epsilon:0.009920974201040588\n",
      "episode:701 steps:81 total reward:-2.600000000000001 epsilon:0.009920974201040588\n",
      "episode:702 steps:20 total reward:0.6199999999999999 epsilon:0.009920974201040588\n",
      "episode:703 steps:22 total reward:0.5799999999999998 epsilon:0.009920974201040588\n",
      "episode:704 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:705 steps:83 total reward:-2.640000000000001 epsilon:0.009920974201040588\n",
      "episode:706 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:707 steps:42 total reward:-1.8200000000000003 epsilon:0.009920974201040588\n",
      "episode:708 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:709 steps:89 total reward:-0.7600000000000011 epsilon:0.009920974201040588\n",
      "episode:710 steps:56 total reward:-0.10000000000000053 epsilon:0.009920974201040588\n",
      "episode:711 steps:9 total reward:0.84 epsilon:0.009920974201040588\n",
      "episode:712 steps:6 total reward:-1.1 epsilon:0.009920974201040588\n",
      "episode:713 steps:6 total reward:-1.1 epsilon:0.009920974201040588\n",
      "episode:714 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:715 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:716 steps:44 total reward:-1.8600000000000003 epsilon:0.009920974201040588\n",
      "episode:717 steps:9 total reward:-1.16 epsilon:0.009920974201040588\n",
      "episode:718 steps:65 total reward:-2.2800000000000007 epsilon:0.009920974201040588\n",
      "episode:719 steps:53 total reward:-2.0400000000000005 epsilon:0.009920974201040588\n",
      "episode:720 steps:22 total reward:0.5799999999999998 epsilon:0.009920974201040588\n",
      "episode:721 steps:36 total reward:0.2999999999999997 epsilon:0.009920974201040588\n",
      "episode:722 steps:33 total reward:-1.6400000000000001 epsilon:0.009920974201040588\n",
      "episode:723 steps:74 total reward:-0.46000000000000085 epsilon:0.009920974201040588\n",
      "episode:724 steps:12 total reward:-1.22 epsilon:0.009920974201040588\n",
      "episode:725 steps:43 total reward:0.1599999999999996 epsilon:0.009920974201040588\n",
      "episode:726 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:727 steps:24 total reward:0.5399999999999998 epsilon:0.009920974201040588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-15 09:06:21,350] Starting new video recorder writing to C:\\Users\\abjilani\\Desktop\\Projects\\DL Nanodegree\\my-experiments\\reinforcement learning\\monitor\\openaigym.video.3.17488.video000729.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:728 steps:40 total reward:-1.7800000000000002 epsilon:0.009920974201040588\n",
      "episode:729 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:730 steps:60 total reward:-0.1800000000000006 epsilon:0.009920974201040588\n",
      "episode:731 steps:53 total reward:-2.0400000000000005 epsilon:0.009920974201040588\n",
      "episode:732 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:733 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:734 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:735 steps:11 total reward:0.8 epsilon:0.009920974201040588\n",
      "episode:736 steps:53 total reward:-0.04000000000000048 epsilon:0.009920974201040588\n",
      "episode:737 steps:61 total reward:-0.20000000000000062 epsilon:0.009920974201040588\n",
      "episode:738 steps:58 total reward:-2.1400000000000006 epsilon:0.009920974201040588\n",
      "episode:739 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:740 steps:77 total reward:-0.5200000000000009 epsilon:0.009920974201040588\n",
      "episode:741 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:742 steps:82 total reward:-2.620000000000001 epsilon:0.009920974201040588\n",
      "episode:743 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:744 steps:70 total reward:-2.380000000000001 epsilon:0.009920974201040588\n",
      "episode:745 steps:39 total reward:-1.7600000000000002 epsilon:0.009920974201040588\n",
      "episode:746 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:747 steps:28 total reward:-1.54 epsilon:0.009920974201040588\n",
      "episode:748 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:749 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:750 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:751 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:752 steps:49 total reward:0.03999999999999948 epsilon:0.009920974201040588\n",
      "episode:753 steps:86 total reward:-0.7000000000000011 epsilon:0.009920974201040588\n",
      "episode:754 steps:60 total reward:-2.1800000000000006 epsilon:0.009920974201040588\n",
      "episode:755 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:756 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:757 steps:8 total reward:-1.1400000000000001 epsilon:0.009920974201040588\n",
      "episode:758 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:759 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:760 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:761 steps:95 total reward:-0.8800000000000012 epsilon:0.009920974201040588\n",
      "episode:762 steps:68 total reward:-2.3400000000000007 epsilon:0.009920974201040588\n",
      "episode:763 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:764 steps:51 total reward:-4.440892098500626e-16 epsilon:0.009920974201040588\n",
      "episode:765 steps:53 total reward:-0.04000000000000048 epsilon:0.009920974201040588\n",
      "episode:766 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:767 steps:97 total reward:-0.9200000000000013 epsilon:0.009920974201040588\n",
      "episode:768 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:769 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:770 steps:8 total reward:0.86 epsilon:0.009920974201040588\n",
      "episode:771 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:772 steps:85 total reward:-2.680000000000001 epsilon:0.009920974201040588\n",
      "episode:773 steps:77 total reward:-0.5200000000000009 epsilon:0.009920974201040588\n",
      "episode:774 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:775 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:776 steps:71 total reward:-0.4000000000000008 epsilon:0.009920974201040588\n",
      "episode:777 steps:35 total reward:0.31999999999999973 epsilon:0.009920974201040588\n",
      "episode:778 steps:93 total reward:-2.840000000000001 epsilon:0.009920974201040588\n",
      "episode:779 steps:13 total reward:0.76 epsilon:0.009920974201040588\n",
      "episode:780 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:781 steps:14 total reward:0.74 epsilon:0.009920974201040588\n",
      "episode:782 steps:89 total reward:-0.7600000000000011 epsilon:0.009920974201040588\n",
      "episode:783 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:784 steps:71 total reward:-0.4000000000000008 epsilon:0.009920974201040588\n",
      "episode:785 steps:95 total reward:-0.8800000000000012 epsilon:0.009920974201040588\n",
      "episode:786 steps:49 total reward:-1.9600000000000004 epsilon:0.009920974201040588\n",
      "episode:787 steps:36 total reward:0.2999999999999997 epsilon:0.009920974201040588\n",
      "episode:788 steps:22 total reward:-1.4200000000000002 epsilon:0.009920974201040588\n",
      "episode:789 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:790 steps:49 total reward:-1.9600000000000004 epsilon:0.009920974201040588\n",
      "episode:791 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:792 steps:30 total reward:0.4199999999999998 epsilon:0.009920974201040588\n",
      "episode:793 steps:87 total reward:-0.7200000000000011 epsilon:0.009920974201040588\n",
      "episode:794 steps:20 total reward:-1.3800000000000001 epsilon:0.009920974201040588\n",
      "episode:795 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:796 steps:30 total reward:0.4199999999999998 epsilon:0.009920974201040588\n",
      "episode:797 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:798 steps:24 total reward:0.5399999999999998 epsilon:0.009920974201040588\n",
      "episode:799 steps:55 total reward:-2.0800000000000005 epsilon:0.009920974201040588\n",
      "episode:800 steps:14 total reward:0.74 epsilon:0.009920974201040588\n",
      "episode:801 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:802 steps:43 total reward:0.1599999999999996 epsilon:0.009920974201040588\n",
      "episode:803 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:804 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:805 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:806 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:807 steps:87 total reward:-0.7200000000000011 epsilon:0.009920974201040588\n",
      "episode:808 steps:66 total reward:-2.3000000000000007 epsilon:0.009920974201040588\n",
      "episode:809 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:810 steps:77 total reward:-0.5200000000000009 epsilon:0.009920974201040588\n",
      "episode:811 steps:32 total reward:-1.62 epsilon:0.009920974201040588\n",
      "episode:812 steps:37 total reward:0.2799999999999997 epsilon:0.009920974201040588\n",
      "episode:813 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:814 steps:9 total reward:-1.16 epsilon:0.009920974201040588\n",
      "episode:815 steps:74 total reward:-2.460000000000001 epsilon:0.009920974201040588\n",
      "episode:816 steps:32 total reward:0.3799999999999998 epsilon:0.009920974201040588\n",
      "episode:817 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:818 steps:52 total reward:-0.020000000000000462 epsilon:0.009920974201040588\n",
      "episode:819 steps:27 total reward:0.47999999999999987 epsilon:0.009920974201040588\n",
      "episode:820 steps:49 total reward:-1.9600000000000004 epsilon:0.009920974201040588\n",
      "episode:821 steps:14 total reward:-1.26 epsilon:0.009920974201040588\n",
      "episode:822 steps:69 total reward:-0.36000000000000076 epsilon:0.009920974201040588\n",
      "episode:823 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:824 steps:33 total reward:-1.6400000000000001 epsilon:0.009920974201040588\n",
      "episode:825 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:826 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:827 steps:18 total reward:0.6599999999999999 epsilon:0.009920974201040588\n",
      "episode:828 steps:15 total reward:0.72 epsilon:0.009920974201040588\n",
      "episode:829 steps:80 total reward:-0.580000000000001 epsilon:0.009920974201040588\n",
      "episode:830 steps:66 total reward:-2.3000000000000007 epsilon:0.009920974201040588\n",
      "episode:831 steps:47 total reward:-1.9200000000000004 epsilon:0.009920974201040588\n",
      "episode:832 steps:8 total reward:0.86 epsilon:0.009920974201040588\n",
      "episode:833 steps:80 total reward:-2.580000000000001 epsilon:0.009920974201040588\n",
      "episode:834 steps:48 total reward:0.0599999999999995 epsilon:0.009920974201040588\n",
      "episode:835 steps:90 total reward:-0.7800000000000011 epsilon:0.009920974201040588\n",
      "episode:836 steps:15 total reward:-1.28 epsilon:0.009920974201040588\n",
      "episode:837 steps:43 total reward:-1.8400000000000003 epsilon:0.009920974201040588\n",
      "episode:838 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:839 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:840 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:841 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:842 steps:94 total reward:-2.860000000000001 epsilon:0.009920974201040588\n",
      "episode:843 steps:44 total reward:-1.8600000000000003 epsilon:0.009920974201040588\n",
      "episode:844 steps:49 total reward:0.03999999999999948 epsilon:0.009920974201040588\n",
      "episode:845 steps:46 total reward:-1.9000000000000004 epsilon:0.009920974201040588\n",
      "episode:846 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:847 steps:36 total reward:0.2999999999999997 epsilon:0.009920974201040588\n",
      "episode:848 steps:52 total reward:-0.020000000000000462 epsilon:0.009920974201040588\n",
      "episode:849 steps:42 total reward:-1.8200000000000003 epsilon:0.009920974201040588\n",
      "episode:850 steps:98 total reward:-0.9400000000000013 epsilon:0.009920974201040588\n",
      "episode:851 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:852 steps:17 total reward:0.6799999999999999 epsilon:0.009920974201040588\n",
      "episode:853 steps:52 total reward:-2.0200000000000005 epsilon:0.009920974201040588\n",
      "episode:854 steps:70 total reward:-0.3800000000000008 epsilon:0.009920974201040588\n",
      "episode:855 steps:14 total reward:-1.26 epsilon:0.009920974201040588\n",
      "episode:856 steps:58 total reward:-2.1400000000000006 epsilon:0.009920974201040588\n",
      "episode:857 steps:8 total reward:0.86 epsilon:0.009920974201040588\n",
      "episode:858 steps:71 total reward:-0.4000000000000008 epsilon:0.009920974201040588\n",
      "episode:859 steps:49 total reward:0.03999999999999948 epsilon:0.009920974201040588\n",
      "episode:860 steps:85 total reward:-0.680000000000001 epsilon:0.009920974201040588\n",
      "episode:861 steps:15 total reward:0.72 epsilon:0.009920974201040588\n",
      "episode:862 steps:21 total reward:0.5999999999999999 epsilon:0.009920974201040588\n",
      "episode:863 steps:42 total reward:-1.8200000000000003 epsilon:0.009920974201040588\n",
      "episode:864 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:865 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:866 steps:70 total reward:-0.3800000000000008 epsilon:0.009920974201040588\n",
      "episode:867 steps:13 total reward:0.76 epsilon:0.009920974201040588\n",
      "episode:868 steps:85 total reward:-0.680000000000001 epsilon:0.009920974201040588\n",
      "episode:869 steps:35 total reward:0.31999999999999973 epsilon:0.009920974201040588\n",
      "episode:870 steps:10 total reward:0.8200000000000001 epsilon:0.009920974201040588\n",
      "episode:871 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:872 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:873 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:874 steps:18 total reward:0.6599999999999999 epsilon:0.009920974201040588\n",
      "episode:875 steps:78 total reward:-0.5400000000000009 epsilon:0.009920974201040588\n",
      "episode:876 steps:24 total reward:0.5399999999999998 epsilon:0.009920974201040588\n",
      "episode:877 steps:30 total reward:0.4199999999999998 epsilon:0.009920974201040588\n",
      "episode:878 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:879 steps:57 total reward:-2.1200000000000006 epsilon:0.009920974201040588\n",
      "episode:880 steps:8 total reward:-1.1400000000000001 epsilon:0.009920974201040588\n",
      "episode:881 steps:68 total reward:-2.3400000000000007 epsilon:0.009920974201040588\n",
      "episode:882 steps:44 total reward:0.13999999999999957 epsilon:0.009920974201040588\n",
      "episode:883 steps:9 total reward:0.84 epsilon:0.009920974201040588\n",
      "episode:884 steps:21 total reward:-1.4000000000000001 epsilon:0.009920974201040588\n",
      "episode:885 steps:16 total reward:-1.3 epsilon:0.009920974201040588\n",
      "episode:886 steps:85 total reward:-2.680000000000001 epsilon:0.009920974201040588\n",
      "episode:887 steps:25 total reward:0.5199999999999998 epsilon:0.009920974201040588\n",
      "episode:888 steps:12 total reward:-1.22 epsilon:0.009920974201040588\n",
      "episode:889 steps:49 total reward:-1.9600000000000004 epsilon:0.009920974201040588\n",
      "episode:890 steps:20 total reward:-1.3800000000000001 epsilon:0.009920974201040588\n",
      "episode:891 steps:12 total reward:-1.22 epsilon:0.009920974201040588\n",
      "episode:892 steps:34 total reward:-1.6600000000000001 epsilon:0.009920974201040588\n",
      "episode:893 steps:7 total reward:-1.12 epsilon:0.009920974201040588\n",
      "episode:894 steps:18 total reward:-1.34 epsilon:0.009920974201040588\n",
      "episode:895 steps:13 total reward:-1.24 epsilon:0.009920974201040588\n",
      "episode:896 steps:5 total reward:-1.08 epsilon:0.009920974201040588\n",
      "episode:897 steps:100 total reward:-2.9800000000000013 epsilon:0.009920974201040588\n",
      "episode:898 steps:7 total reward:-1.12 epsilon:0.009920974201040588\n",
      "episode:899 steps:25 total reward:-1.4800000000000002 epsilon:0.009920974201040588\n",
      "episode:900 steps:14 total reward:-1.26 epsilon:0.009920974201040588\n",
      "episode:901 steps:31 total reward:-1.6 epsilon:0.009920974201040588\n",
      "episode:902 steps:11 total reward:-1.2 epsilon:0.009920974201040588\n",
      "episode:903 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:904 steps:15 total reward:-1.28 epsilon:0.009920974201040588\n",
      "episode:905 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:906 steps:9 total reward:-1.16 epsilon:0.009920974201040588\n",
      "episode:907 steps:10 total reward:-1.18 epsilon:0.009920974201040588\n",
      "episode:908 steps:6 total reward:-1.1 epsilon:0.009920974201040588\n",
      "episode:909 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:910 steps:5 total reward:-1.08 epsilon:0.009920974201040588\n",
      "episode:911 steps:5 total reward:-1.08 epsilon:0.009920974201040588\n",
      "episode:912 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:913 steps:27 total reward:-1.52 epsilon:0.009920974201040588\n",
      "episode:914 steps:21 total reward:-1.4000000000000001 epsilon:0.009920974201040588\n",
      "episode:915 steps:34 total reward:-1.6600000000000001 epsilon:0.009920974201040588\n",
      "episode:916 steps:10 total reward:-1.18 epsilon:0.009920974201040588\n",
      "episode:917 steps:23 total reward:-1.4400000000000002 epsilon:0.009920974201040588\n",
      "episode:918 steps:5 total reward:-1.08 epsilon:0.009920974201040588\n",
      "episode:919 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:920 steps:27 total reward:-1.52 epsilon:0.009920974201040588\n",
      "episode:921 steps:24 total reward:-1.4600000000000002 epsilon:0.009920974201040588\n",
      "episode:922 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:923 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:924 steps:8 total reward:-1.1400000000000001 epsilon:0.009920974201040588\n",
      "episode:925 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:926 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:927 steps:5 total reward:-1.08 epsilon:0.009920974201040588\n",
      "episode:928 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:929 steps:32 total reward:-1.62 epsilon:0.009920974201040588\n",
      "episode:930 steps:31 total reward:-1.6 epsilon:0.009920974201040588\n",
      "episode:931 steps:17 total reward:-1.32 epsilon:0.009920974201040588\n",
      "episode:932 steps:9 total reward:-1.16 epsilon:0.009920974201040588\n",
      "episode:933 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:934 steps:21 total reward:-1.4000000000000001 epsilon:0.009920974201040588\n",
      "episode:935 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:936 steps:15 total reward:-1.28 epsilon:0.009920974201040588\n",
      "episode:937 steps:9 total reward:-1.16 epsilon:0.009920974201040588\n",
      "episode:938 steps:12 total reward:-1.22 epsilon:0.009920974201040588\n",
      "episode:939 steps:45 total reward:-1.8800000000000003 epsilon:0.009920974201040588\n",
      "episode:940 steps:10 total reward:-1.18 epsilon:0.009920974201040588\n",
      "episode:941 steps:8 total reward:-1.1400000000000001 epsilon:0.009920974201040588\n",
      "episode:942 steps:44 total reward:-1.8600000000000003 epsilon:0.009920974201040588\n",
      "episode:943 steps:8 total reward:-1.1400000000000001 epsilon:0.009920974201040588\n",
      "episode:944 steps:14 total reward:-1.26 epsilon:0.009920974201040588\n",
      "episode:945 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:946 steps:29 total reward:-1.56 epsilon:0.009920974201040588\n",
      "episode:947 steps:28 total reward:-1.54 epsilon:0.009920974201040588\n",
      "episode:948 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:949 steps:12 total reward:-1.22 epsilon:0.009920974201040588\n",
      "episode:950 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:951 steps:33 total reward:-1.6400000000000001 epsilon:0.009920974201040588\n",
      "episode:952 steps:7 total reward:-1.12 epsilon:0.009920974201040588\n",
      "episode:953 steps:15 total reward:-1.28 epsilon:0.009920974201040588\n",
      "episode:954 steps:62 total reward:-2.2200000000000006 epsilon:0.009920974201040588\n",
      "episode:955 steps:19 total reward:-1.36 epsilon:0.009920974201040588\n",
      "episode:956 steps:31 total reward:-1.6 epsilon:0.009920974201040588\n",
      "episode:957 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:958 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n",
      "episode:959 steps:5 total reward:-1.08 epsilon:0.009920974201040588\n",
      "episode:960 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:961 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:962 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:963 steps:5 total reward:-1.08 epsilon:0.009920974201040588\n",
      "episode:964 steps:2 total reward:-1.02 epsilon:0.009920974201040588\n",
      "episode:965 steps:9 total reward:-1.16 epsilon:0.009920974201040588\n",
      "episode:966 steps:79 total reward:-2.560000000000001 epsilon:0.009920974201040588\n",
      "episode:967 steps:15 total reward:-1.28 epsilon:0.009920974201040588\n",
      "episode:968 steps:27 total reward:-1.52 epsilon:0.009920974201040588\n",
      "episode:969 steps:74 total reward:-2.460000000000001 epsilon:0.009920974201040588\n",
      "episode:970 steps:7 total reward:-1.12 epsilon:0.009920974201040588\n",
      "episode:971 steps:10 total reward:-1.18 epsilon:0.009920974201040588\n",
      "episode:972 steps:3 total reward:-1.04 epsilon:0.009920974201040588\n",
      "episode:973 steps:4 total reward:-1.06 epsilon:0.009920974201040588\n"
     ]
    }
   ],
   "source": [
    "reward_list=[]\n",
    "state = env.reset()\n",
    "for episode in range(episodes):\n",
    "    total_reward = 0\n",
    "    state = env.reset()\n",
    "    for step in range(steps):\n",
    "        if epsilon > np.random.rand():\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(bot.predict(np.reshape(state_lkup[state], (-1, env.observation_space.n))))\n",
    "        next_state, reward, done, prob = env.step(action)\n",
    "        if done and reward==0:\n",
    "            reward = -1\n",
    "        if not done and reward==0:\n",
    "            reward = -0.02\n",
    "        memory.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "        total_reward = total_reward + reward\n",
    "        if done:\n",
    "            print('episode:{} steps:{} total reward:{} epsilon:{}'.format(episode + 1, step + 1, total_reward, epsilon))\n",
    "            reward_list.append(total_reward)\n",
    "            break\n",
    "        \n",
    "        minibatch = [memory[ii] for ii in np.random.choice(range(len(memory)), batch_size)]\n",
    "        states = [each[0] for each in minibatch]\n",
    "        actions = [each[1] for each in minibatch]\n",
    "        rewards = [each[2] for each in minibatch]\n",
    "        next_states = [each[3] for each in minibatch]\n",
    "        dones = [each[4] for each in minibatch]\n",
    "        \n",
    "        next_states = np.reshape([state_lkup[state] for state in next_states], [-1,env.observation_space.n])\n",
    "        states = np.reshape([state_lkup[state] for state in states], [-1,env.observation_space.n])\n",
    "        actions = np.reshape(actions, (batch_size, 1))\n",
    "        targetQs = bot.predict(next_states)\n",
    "        episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "        targetQs[episode_ends] = (0, 0, 0, 0)\n",
    "        \n",
    "        targets = rewards + gamma * np.max(targetQs, axis=1)\n",
    "        targets_f = bot.predict(states)\n",
    "        \n",
    "        for pos in range(len(actions)):\n",
    "            targets_f[pos,actions[pos]] = targets[pos]\n",
    "        \n",
    "        bot.fit(states, targets_f, epochs=1, verbose=0)\n",
    "    if epsilon > epsilon_stop:\n",
    "        epsilon = epsilon * epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2290ceb0b00>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWhuA9197AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2290b99dc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.plot(reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-15 09:01:37,571] [FrozenLake-v0] Uploading 2000 episodes of training data\n",
      "[2017-07-15 09:01:41,647] [FrozenLake-v0] Uploading videos of 12 training episodes (1437 bytes)\n",
      "[2017-07-15 09:01:42,273] [FrozenLake-v0] Creating evaluation object from ./monitor with learning curve and training video\n",
      "[2017-07-15 09:01:42,807] \n",
      "****************************************************\n",
      "You successfully uploaded your evaluation on FrozenLake-v0 to\n",
      "OpenAI Gym! You can find it at:\n",
      "\n",
      "    https://gym.openai.com/evaluations/eval_LR1qmq6jQa2i3PU82MCd8A\n",
      "\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "gym.upload('./monitor', api_key='sk_Iq0FtSUSFyL9rQx6CITg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
